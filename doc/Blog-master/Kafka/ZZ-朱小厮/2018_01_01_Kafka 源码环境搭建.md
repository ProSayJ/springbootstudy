title: Kafka 源码环境搭建
date: 2018-01-01
tag: 
categories: Kafka
permalink: Kafka/build-debugging-environment
author: 朱小厮
from_url: https://blog.csdn.net/u013256816/article/details/78533725
wechat_url: 

-------

摘要: 原创出处 https://blog.csdn.net/u013256816/article/details/78533725 「朱小厮」欢迎转载，保留摘要，谢谢！

- [NOTE: When you change this version number, you should also make sure to update](http://www.iocoder.cn/Kafka/build-debugging-environment/)
- [the version numbers in tests/kafkatest/__init__.py and kafka-merge-pr.py.](http://www.iocoder.cn/Kafka/build-debugging-environment/)
- [是否允许topic被删除，设置为true则topic可以被删除，](http://www.iocoder.cn/Kafka/build-debugging-environment/)
- [开启这个功能方便Kafka在运行一段时间之后，能够删除一些不需要的临时topic](http://www.iocoder.cn/Kafka/build-debugging-environment/)
- [禁用自动创建topic的功能](http://www.iocoder.cn/Kafka/build-debugging-environment/)
- [存储log文件的目录，默认值为/tmp/kafka-logs](http://www.iocoder.cn/Kafka/build-debugging-environment/)
- [示例是在Windows环境下运行，所以需要修改这个配置，注意这里的双反斜杠。](http://www.iocoder.cn/Kafka/build-debugging-environment/)
- [配置kafka依赖的zookeeper路径地址，这里的前提是在本地开启了一个zookeeper的服务](http://www.iocoder.cn/Kafka/build-debugging-environment/)
- [如果本地没有zookeeper服务，可以参考下一节中zookeeper的安装、配置及运行](http://www.iocoder.cn/Kafka/build-debugging-environment/)

-------

![](http://www.iocoder.cn/images/common/wechat_mp_2017_07_31.jpg)

> 🙂🙂🙂关注**微信公众号：【芋道源码】**有福利：
> 1. RocketMQ / MyCAT / Sharding-JDBC **所有**源码分析文章列表
> 2. RocketMQ / MyCAT / Sharding-JDBC **中文注释源码 GitHub 地址**
> 3. 您对于源码的疑问每条留言**都**将得到**认真**回复。**甚至不知道如何读源码也可以请教噢**。
> 4. **新的**源码解析文章**实时**收到通知。**每周更新一篇左右**。
> 5. **认真的**源码交流微信群。

-------

本文主要讲述的是如何搭建Kafka的源码环境，主要针对的Windows操作系统下IntelliJ IDEA编译器，其余操作系统或者IDE可以类推。

### 1.安装和配置JDK

确认JDK版本至少为1.7，最好是1.8及以上。使用java -version命令来查看当前JDK的版本，示例如下：

```
C:\Users\hidden> java -version
java version "1.8.0_112"
Java(TM) SE Runtime Environment (build 1.8.0_112-b15)
Java HotSpot(TM) 64-Bit Server VM (build 25.112-b15, mixed mode)
```

### 2.下载并安装配置Gradle

下载地址为：<https://gradle.org/releases/>，笔者使用的版本是3.1。一般只需要将下载的包解压，然后再将$的路径添加到环境变量中即可，其中GRADLE_HOME/bin的路径添加到环境变量Path中即可，其中$GRADLE_HOME指的是Gradle的根目录。可以使用gradle -v命令来验证Gradle是否已经配置完成，示例如下：

```
C:\Users\hidden>gradle -v

------------------------------------------------------------
Gradle 3.1
------------------------------------------------------------

Build time:   2016-09-19 10:53:53 UTC
Revision:     13f38ba699afd86d7cdc4ed8fd7dd3960c0b1f97

Groovy:       2.4.7
Ant:          Apache Ant(TM) version 1.9.6 compiled on June 29 2015
JVM:          1.8.0_112 (Oracle Corporation 25.112-b15)
OS:           Windows 10 10.0 amd64
```

### 3.下载并安装配置Scala

下载地址为：<http://www.scala-lang.org/download/all.html>，目前最新的版本是2.12.4，不过笔者这里使用的版本是2.11.11。如Gradle一样，只需要解压并将$的路径添加到环境变量即可，其中SCALA_HOME/bin的路径添加到环境变量Path即可，其中$SCALA_HOME指的是Scala的根目录。可以使用scala -version命令来验证scala是否已经配置完成，示例如下：

```
C:\Users\hidden>scala -version
Scala code runner version 2.11.11 -- Copyright 2002-2017, LAMP/EPFL
```

### 4. 构建Kafka源码环境

Kafka下载地址为：<http://kafka.apache.org/downloads>，目前最新的版本是1.0.0。将下载的压缩包解压，并在Kafka的根目录执行gradle idea命令进行构建，如果你使用的是Eclipse，则只需采用gradle eclipse命令构建即可。构建细节如下所示：

```
D:\IntelliJ IDEA Files\kafka-sources\kafka-1.0.0-src>gradle idea
Starting a Gradle Daemon, 2 incompatible and 1 stopped Daemons could not be reused, use --status for details
Building project 'core' with Scala version 2.11.11
:ideaModule
:ideaProject
(......省略若干......)
:streams:examples:ideaModule
:streams:examples:idea

BUILD SUCCESSFUL

Total time: 1 mins 11.991 secs
```

之后将Kafka导入到IDEA中即可。不过这样还没有结束，对于IDEA而言，还需要安装Scala插件，在Setting->Plugin中搜索scala并安装，可以参考下图，笔者这里是已经安装好的状态：

![这里写图片描述](http://static.iocoder.cn/csdn/20171114004759447?)

### 5. 配置Kafka源码环境

前面几个步骤执行完成后就可以很舒适的阅读Kafka的源码，但是如果需要启动Kafka的服务还需要一些额外的步骤。

首先确保gradle.properties配置文件中的scalaVersion与安装的一致。gradle.properties配置文件的细节如下：

```
group=org.apache.kafka
# NOTE: When you change this version number, you should also make sure to update
# the version numbers in tests/kafkatest/__init__.py and kafka-merge-pr.py.
version=1.0.0
scalaVersion=2.11.11
task=build
org.gradle.jvmargs=-XX:MaxPermSize=512m -Xmx1024m -Xss2m
```

如果更改了scalaVersion，需要重新执行gradle idea命令来重新构建。虽然很多时候在操作系统中安装其他版本的Scala也并没有什么问题，比如安装2.12.4版本。但是有些情况下运行Kafka时会出现一些异常，而这些异常却又是由于Scala版本不一致而引起的，比如会出现下面示例中的报错：

```Java
[2017-11-13 17:09:21,119] FATAL  (kafka.Kafka$)
java.lang.NoSuchMethodError: scala.collection.TraversableOnce.$init$(Lscala/collection/TraversableOnce;)V
    at kafka.message.MessageSet.<init>(MessageSet.scala:72)
    at kafka.message.ByteBufferMessageSet.<init>(ByteBufferMessageSet.scala:129)
    at kafka.message.MessageSet$.<init>(MessageSet.scala:32)
    at kafka.message.MessageSet$.<clinit>(MessageSet.scala)
    at kafka.server.Defaults$.<init>(KafkaConfig.scala:52)
    at kafka.server.Defaults$.<clinit>(KafkaConfig.scala)
    at kafka.server.KafkaConfig$.<init>(KafkaConfig.scala:686)
    at kafka.server.KafkaConfig$.<clinit>(KafkaConfig.scala)
    at kafka.server.KafkaServerStartable$.fromProps(KafkaServerStartable.scala:28)
    at kafka.Kafka$.main(Kafka.scala:82)
    at kafka.Kafka.main(Kafka.scala)
```

所以为了省去一些不必要的麻烦，还是建议读者在安装Scala版本之前先查看下Kafka源码中gradle.properties文件中配置的scalaVersion。

再确保了scalaVersion之后，需要将config目录下的log4j.properties文件拷贝到core/src/main/scala目录下，这样可以让Kafka在运行时能够输出日志信息，可以参考下图：

![这里写图片描述](http://static.iocoder.cn/csdn/20171114004845189?)

之后还需要配置server.properties文件，一般只需要修改以下一些配置项：

```
# 是否允许topic被删除，设置为true则topic可以被删除，
# 开启这个功能方便Kafka在运行一段时间之后，能够删除一些不需要的临时topic
delete.topic.enable=true
# 禁用自动创建topic的功能
auto.create.topics.enable=false
# 存储log文件的目录，默认值为/tmp/kafka-logs
# 示例是在Windows环境下运行，所以需要修改这个配置，注意这里的双反斜杠。
log.dir=D:\\kafka\\tmp\\kafka-logs
# 配置kafka依赖的zookeeper路径地址，这里的前提是在本地开启了一个zookeeper的服务
# 如果本地没有zookeeper服务，可以参考下一节中zookeeper的安装、配置及运行
zookeeper.connect=localhost:2181/kafka
```

之后配置Kafka的启动参数，详细参考下图：

![这里写图片描述](http://static.iocoder.cn/csdn/20171114004857498?)

这里配置Main class为kafka.Kafka，并制定启动时所需要的配置文件地址，即：config/server.properties。配置JMX_PORT是为了方便搜集Kafka自身的Metrics数据。

如此便可以顺利的运行Kafka服务了（第一次启动时会有一个耗时较长的编译过程），部分启动日志如下：

```Java
[2017-11-14 00:24:14,472] INFO KafkaConfig values:
    advertised.host.name = null
    advertised.listeners = null
    advertised.port = null
    authorizer.class.name =
(......省略若干......)
[2017-11-14 00:24:35,001] INFO Registered broker 0 at path /brokers/ids/0 with addresses: EndPoint(LAPTOP-1IN9UPT7,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.utils.ZkUtils)
[2017-11-14 00:24:35,019] INFO Kafka version : 1.0.0 (org.apache.kafka.common.utils.AppInfoParser)
[2017-11-14 00:24:35,020] INFO Kafka commitId : e89bffd6b2eff799 (org.apache.kafka.common.utils.AppInfoParser)
[2017-11-14 00:24:35,021] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
```

### 6. Zookeeper的安装、配置及启动

Kafka需要使用Zookeeper来管理元数据，比如记录topic、partitions（分区）以及replica（副本）的分配信息。由于这里只是阐述如何构建Kafka的源码环境搭建，所以这里的Zookeeper的安装也以极简为主，即采用单机配置。Zookeeper下载地址为：<http://zookeeper.apache.org/releases.html>，下载之后解压，然后将$目录下的重命名为，其中ZOOKEEPER_HOME目录下的conf/zoo_sample.cfg重命名为zoo.cfg，其中$ZOOKEEPER_HOME指的是ZooKeeper的根目录。

修改$ZOOKEEPER_HOME/conf/zoo.cfg配置，示例配置如下（其余配置可以不做修改）：

```
dataDir=D:\\zookeeper-3.4.10\\tmp\\zookeeper\\data
```

将$ZOOKEEPER_HOME/bin配置到Path中，之后直接运行zkServer命令即可开启Zookeeper服务。示例如下：

```Cmd
C:\Users\hidden>zkServer

C:\Users\hidden>call "C:\Program Files\Java\jdk1.8.0_112"\bin\java "-Dzookeeper.log.dir=D:\zookeeper-3.4.10\bin\.." "-Dzookeeper.root.logger=INFO,CONSOLE" -cp "D:\zookeeper-3.4.10\bin\..\build\classes;D:\zookeeper-3.4.10\bin\..\build\lib\*;D:\zookeeper-3.4.10\bin\..\*;D:\zookeeper-3.4.10\bin\..\lib\*;D:\zookeeper-3.4.10\bin\..\conf" org.apache.zookeeper.server.quorum.QuorumPeerMain "D:\zookeeper-3.4.10\bin\..\conf\zoo.cfg"
2017-11-14 00:44:20,135 [myid:] - INFO  [main:QuorumPeerConfig@134] - Reading configuration from: D:\zookeeper-3.4.10\bin\..\conf\zoo.cfg
2017-11-14 00:44:20,147 [myid:] - INFO  [main:DatadirCleanupManager@78] - autopurge.snapRetainCount set to 3
2017-11-14 00:44:20,147 [myid:] - INFO  [main:DatadirCleanupManager@79] - autopurge.purgeInterval set to 0
2017-11-14 00:44:20,147 [myid:] - INFO  [main:DatadirCleanupManager@101] - Purge task is not scheduled.
2017-11-14 00:44:20,150 [myid:] - WARN  [main:QuorumPeerMain@113] - Either no config or no quorum defined in config, running  in standalone mode
2017-11-14 00:44:20,250 [myid:] - INFO  [main:QuorumPeerConfig@134] - Reading configuration from: D:\zookeeper-3.4.10\bin\..\conf\zoo.cfg
2017-11-14 00:44:20,250 [myid:] - INFO  [main:ZooKeeperServerMain@96] - Starting server
```

# 666. 彩蛋

如果你对 Kafka 并发感兴趣，欢迎加入我的知识一起交流。

![知识星球](http://www.iocoder.cn/images/Architecture/2017_12_29/01.png)